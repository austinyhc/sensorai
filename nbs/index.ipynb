{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from sensorai.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to sensorai\n",
    "\n",
    "> Make deep learning is more accessibe to apply for sensors on low-cost edge devices\n",
    "\n",
    "`sensorai` is a lightweight wrapper for the deep learning library [TensorFlow Keras](https://www.tensorflow.org/guide/keras/sequential_model) (and other libraries) to help build, train, and deploy deep learning models. Inspired by ML framework extensions like *fastai* and *ludwig*, `waveai` is designed to make deep learning and AI more accessible and easier to specifically apply for sensors on low-cost edge devices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1% Better Everyday\n",
    "\n",
    "- estimate an optimal learning rate for your model given your data using a Leanring Rate Finder\n",
    "- utilize learning rate schedules such as the [triangular policy](https://arxiv.org/abs/1506.01186), the [1cycle policy](https://arxiv.org/abs/1803.09820), and [SGDR](https://arxiv.org/abs/1608.03983) to effectively minimize loss and improve generalization\n",
    "- load and preprocess waveform-baesd data from a variety of formats\n",
    "- inspect data points that were misclassified and [provide explanations](https://eli5.readthedocs.io/en/latest/) to help improve your model\n",
    "- leverage a simple prediction API for saving and deploying both models and data-preprocessing steps to make predictions on new raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install sensorai`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last but not least, it is highly recommended by `nbdev` to run `nbdev_install_git_hooks` after first clone a repo. This sets up git hooks, which clean up the notebooks to removce the extraneous metadata stored in the notebooks which causes unnecessary merge conflicts.\n",
    "\n",
    "Also, before submitting a PR, chech that the local library and notebooks match. The script `nbdev_diff_nbs` can let you know if there is a difference between the local library and the notebooks.\n",
    "- If you made a change to the notebooks in one of the exported cells, you can export it to the library with `nbdev_build_lib` or `make fastai`\n",
    "- If you made a change to the library, you can export it back to the notebooks with `nbdev_update_lib`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the tests in parallel, launch:\n",
    "\n",
    "`nbdev_test_nbs` or `make test`\n",
    "\n",
    "For all the tests to pass, you'll need to install the following optional dependencies:\n",
    "```bash\n",
    "pip install \"sentencepiece<0.1.90\" wandb tensorboard albumentations pydicom opencv-python scikit-image pyarrow kornia \\\n",
    "    catalyst captum neptune-cli\n",
    "```\n",
    "\n",
    "Tests are written using `nbdev`, for example see the documentation for `test_eq`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker Container\n",
    "> Do I need to create my own docker images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
